{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac0e36886a364e8aa293880666e09458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84184e1908b44ca0919c0055b6bd6102",
              "IPY_MODEL_3b827192f4d84a0f8c0d7c3ec79b9c0c",
              "IPY_MODEL_6ad7bc326aac4b9f883d64fcb9569904"
            ],
            "layout": "IPY_MODEL_33dc792e178942f492cbb7bf708a38c0"
          }
        },
        "84184e1908b44ca0919c0055b6bd6102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b8e08e93d74e61871280e165431da9",
            "placeholder": "​",
            "style": "IPY_MODEL_13630c9abb384f6fbc2721df411fb53e",
            "value": "model.safetensors: 100%"
          }
        },
        "3b827192f4d84a0f8c0d7c3ec79b9c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a7e36e322846b2b27fef4b1ae9d4f2",
            "max": 21355344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2590b7ea0c4e3f8423f25c9e2c8914",
            "value": 21355344
          }
        },
        "6ad7bc326aac4b9f883d64fcb9569904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071b716bec834d66949a6b6aba2adadb",
            "placeholder": "​",
            "style": "IPY_MODEL_ae9a1d21d30543b5a4212108cc2a0483",
            "value": " 21.4M/21.4M [00:00&lt;00:00, 59.2MB/s]"
          }
        },
        "33dc792e178942f492cbb7bf708a38c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b8e08e93d74e61871280e165431da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13630c9abb384f6fbc2721df411fb53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8a7e36e322846b2b27fef4b1ae9d4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2590b7ea0c4e3f8423f25c9e2c8914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "071b716bec834d66949a6b6aba2adadb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae9a1d21d30543b5a4212108cc2a0483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "H4raJkXb_EO-",
        "outputId": "f013b132-ab8b-4e86-aed8-4c1a720f85b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3dd2b2bb-a98d-4054-88a3-73aee8e52c7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3dd2b2bb-a98d-4054-88a3-73aee8e52c7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Kaggle API 1.7.4.5\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import os, shutil\n",
        "fname = next(iter(uploaded))  # 첫 파일명\n",
        "if fname != \"kaggle.json\":\n",
        "    shutil.move(fname, \"kaggle.json\")\n",
        "\n",
        "!pip -q install kaggle\n",
        "!mkdir -p ~/.kaggle /root/.config/kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!cp kaggle.json /root/.config/kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json /root/.config/kaggle/kaggle.json\n",
        "\n",
        "!kaggle --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "KAGGLE_USERNAME = \"kwontaejin\"\n",
        "KAGGLE_KEY = \"26103524\"\n",
        "os.environ[\"kwontaejin\"] = KAGGLE_USERNAME\n",
        "os.environ[\"26103524\"] = KAGGLE_KEY\n",
        "\n",
        "!pip -q install kaggle"
      ],
      "metadata": {
        "id": "K0jZoyBuB0PJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMP=\"aikuthon9th\"\n",
        "!kaggle competitions download -c {COMP}\n",
        "!mkdir -p data\n",
        "!unzip -q -o {COMP}.zip -d data\n",
        "\n",
        "!ls -al data | sed -n '1,120p'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J05fC8iDCUw7",
        "outputId": "a56b43cc-6213-4d2d-bf90-60bbe23e4daa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading aikuthon9th.zip to /content\n",
            "100% 4.04G/4.04G [00:38<00:00, 40.8MB/s]\n",
            "100% 4.04G/4.04G [00:38<00:00, 112MB/s] \n",
            "total 392\n",
            "drwxr-xr-x 4 root root   4096 Aug 29 13:59 .\n",
            "drwxr-xr-x 1 root root   4096 Aug 29 13:58 ..\n",
            "drwxr-xr-x 2 root root  40960 Aug 29 13:58 test_images\n",
            "drwxr-xr-x 2 root root 266240 Aug 29 13:59 train_images\n",
            "-rw-r--r-- 1 root root  77601 Aug 26 08:28 train_metadata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install timm albumentations opencv-python torchmetrics==1.4.0\n",
        "\n",
        "import os, glob, math, random, cv2, numpy as np, pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "CFG = dict(\n",
        "    seed=42,\n",
        "    folds=5,\n",
        "    img_size=224,            #  224로 다운스케일해서 사용\n",
        "    num_classes=6,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    num_workers=2,\n",
        "    accum_steps=2,\n",
        "    lr=3e-4,\n",
        "    weight_decay=5e-2,\n",
        "    warmup_epochs=3,\n",
        "    ema=True,\n",
        "    model_name=\"vit_hybrid_r50_s16_224\",\n",
        "    root=\"data\",\n",
        "    train_dir_name=\"train_images\",   # 원본 512×512\n",
        "    test_dir_name=\"test_images\",     # 원본 512×512\n",
        "    meta_csv=\"train_metadata.csv\",\n",
        "    cb_beta=0.999, cb_gamma=1.5,     # CB-Focal\n",
        "    sampler_alpha=0.0,                # oversampling\n",
        ")\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "set_seed(CFG[\"seed\"])\n",
        "\n",
        "ROOT   = CFG[\"root\"]\n",
        "TRAIND = os.path.join(ROOT, CFG[\"train_dir_name\"])\n",
        "TESTD  = os.path.join(ROOT, CFG[\"test_dir_name\"])\n",
        "META   = os.path.join(ROOT, CFG[\"meta_csv\"])\n",
        "\n",
        "assert os.path.exists(TRAIND), f\"Not found: {TRAIND}\"\n",
        "assert os.path.exists(TESTD),  f\"Not found: {TESTD}\"\n",
        "assert os.path.exists(META),   f\"Not found: {META}\"\n",
        "\n",
        "EXTS = [\"*.png\"]\n",
        "\n",
        "def scan_files(dirpath):\n",
        "    files=[]\n",
        "    for ext in EXTS: files += glob.glob(os.path.join(dirpath, ext))\n",
        "    def sk(p):\n",
        "        s = os.path.splitext(os.path.basename(p))[0]\n",
        "        try: return (0, int(s))\n",
        "        except: return (1, s)\n",
        "    return sorted(files, key=sk)"
      ],
      "metadata": {
        "id": "TD3WCbw4CXMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1a6ab5-8c7e-4af6-9a2e-08d10a635881"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/868.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/868.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KoRwA0FSHUSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "de5690c5",
        "outputId": "722a364e-78ab-40ad-809c-35ad7a7097a0"
      },
      "source": [
        "train_files = scan_files(TRAIND)\n",
        "train_meta = pd.read_csv(META)\n",
        "\n",
        "print(\"Number of training images:\", len(train_files))\n",
        "display(train_meta.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 9699\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   id  label\n",
              "0   1      0\n",
              "1   2      1\n",
              "2   3      0\n",
              "3   4      3\n",
              "4   5      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ac8628-bc8e-4da3-845d-5239feca9042\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ac8628-bc8e-4da3-845d-5239feca9042')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0ac8628-bc8e-4da3-845d-5239feca9042 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0ac8628-bc8e-4da3-845d-5239feca9042');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6027bf79-7886-46fb-a5bb-418d0ad02c84\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6027bf79-7886-46fb-a5bb-418d0ad02c84')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6027bf79-7886-46fb-a5bb-418d0ad02c84 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(train_meta\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "049aaaa6"
      },
      "source": [
        "# Task\n",
        "Modify the code in the selected cell to address the class imbalance issue for labels 1, 2, and 5 in the dataset loaded from \"/content/train_metadata.csv\". The original images are 512x512, but the input size should be 224x224. Implement dropout and mixup techniques and use the efficientnet-b0 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00c21669"
      },
      "source": [
        "## 데이터셋 클래스 불균형 확인\n",
        "\n",
        "### Subtask:\n",
        "`train_metadata.csv` 파일에서 각 레이블의 분포를 다시 한번 확인하여 클래스 불균형 정도를 파악합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e486cd1d"
      },
      "source": [
        "**Reasoning**:\n",
        "The `train_meta` DataFrame is already loaded and contains the label information. I need to calculate the value counts for the 'label' column to check the class distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe98a68d",
        "outputId": "b1097589-9f4b-4965-c7b9-c87d9bd7b4c6"
      },
      "source": [
        "label_counts = train_meta['label'].value_counts().sort_index()\n",
        "print(\"Label distribution:\")\n",
        "print(label_counts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution:\n",
            "label\n",
            "0    3000\n",
            "1     200\n",
            "2     499\n",
            "3    3000\n",
            "4    2200\n",
            "5     800\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b21c24b"
      },
      "source": [
        "## 데이터 전처리 및 증강\n",
        "\n",
        "### Subtask:\n",
        "이미지 크기를 224x224로 조정하고, 클래스 불균형 해소를 위해 오버샘플링 또는 다른 기법을 고려합니다. 또한, dropout과 mixup을 활용한 데이터 증강 기법을 정의합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "541a1a98"
      },
      "source": [
        "**Reasoning**:\n",
        "Define Albumentations transformations for training and validation, and calculate class weights for WeightedRandomSampler.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0620f542",
        "outputId": "0a19b1c3-1376-4d50-e27f-89822a8253a2"
      },
      "source": [
        "train_transform = A.Compose([\n",
        "    A.Resize(CFG[\"img_size\"], CFG[\"img_size\"]),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=10, p=0.5),\n",
        "    A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(CFG[\"img_size\"], CFG[\"img_size\"]),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Calculate class weights for WeightedRandomSampler\n",
        "class_counts = train_meta['label'].value_counts().sort_index()\n",
        "class_weights = 1. / class_counts.values\n",
        "weights = class_weights[train_meta['label'].values]\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, num_classes=CFG[\"num_classes\"]):\n",
        "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0.:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).cuda()\n",
        "    mixed_x = lam * x + (1 - lam) * x[index,:]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e73c9c2"
      },
      "source": [
        "## 모델 정의\n",
        "\n",
        "### Subtask:\n",
        "EfficientNet-B0 모델을 로드하고, 데이터셋의 클래스 수에 맞게 모델의 마지막 레이어를 수정합니다. dropout을 모델에 적용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b8ba3e0"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the efficientnet_b0 model, modify its classifier layer for the correct number of classes, and add a dropout layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ac0e36886a364e8aa293880666e09458",
            "84184e1908b44ca0919c0055b6bd6102",
            "3b827192f4d84a0f8c0d7c3ec79b9c0c",
            "6ad7bc326aac4b9f883d64fcb9569904",
            "33dc792e178942f492cbb7bf708a38c0",
            "33b8e08e93d74e61871280e165431da9",
            "13630c9abb384f6fbc2721df411fb53e",
            "b8a7e36e322846b2b27fef4b1ae9d4f2",
            "8f2590b7ea0c4e3f8423f25c9e2c8914",
            "071b716bec834d66949a6b6aba2adadb",
            "ae9a1d21d30543b5a4212108cc2a0483"
          ]
        },
        "collapsed": true,
        "id": "e08dc43f",
        "outputId": "239ab35f-a7f6-4b0a-8df3-156eb010b2bf"
      },
      "source": [
        "def build_model(model_name=CFG[\"model_name\"], num_classes=CFG[\"num_classes\"], pretrained=True):\n",
        "    model = timm.create_model(model_name, pretrained=pretrained)\n",
        "    # Get the number of input features for the classifier\n",
        "    in_features = model.get_classifier().in_features\n",
        "\n",
        "    # Add dropout before the classifier\n",
        "    dropout_rate = CFG.get(\"dropout_rate\", 0.2) # Use default if not in CFG\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_rate),\n",
        "        nn.Linear(in_features, num_classes)\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "CFG[\"model_name\"] = \"efficientnet_b0\" # Update model name in CFG\n",
        "CFG[\"dropout_rate\"] = 0.2 # Add dropout rate to CFG\n",
        "\n",
        "model = build_model(model_name=CFG[\"model_name\"], num_classes=CFG[\"num_classes\"])\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac0e36886a364e8aa293880666e09458"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNet(\n",
            "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNormAct2d(\n",
            "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "    (drop): Identity()\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (blocks): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): DepthwiseSeparableConv(\n",
            "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): InvertedResidual(\n",
            "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): InvertedResidual(\n",
            "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): InvertedResidual(\n",
            "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): InvertedResidual(\n",
            "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): InvertedResidual(\n",
            "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): InvertedResidual(\n",
            "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (bn2): BatchNormAct2d(\n",
            "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (aa): Identity()\n",
            "        (se): SqueezeExcite(\n",
            "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (gate): Sigmoid()\n",
            "        )\n",
            "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNormAct2d(\n",
            "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          (drop): Identity()\n",
            "          (act): Identity()\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn2): BatchNormAct2d(\n",
            "    1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "    (drop): Identity()\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=1280, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7342ea8"
      },
      "source": [
        "## 손실 함수 및 옵티마이저 정의\n",
        "\n",
        "### Subtask:\n",
        "클래스 불균형을 고려한 손실 함수 (예: Weighted Cross Entropy 또는 CB-Focal)와 옵티마이저를 정의합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f63b47de"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary modules, calculate class weights, and define the loss function and optimizer based on the provided configurations and class counts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb392a2b",
        "outputId": "33d917ae-efe7-4578-f616-8b9cb2558e00"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Calculate class weights based on the inverse of the class counts\n",
        "class_counts = train_meta['label'].value_counts().sort_index()\n",
        "class_weights = 1. / torch.tensor(class_counts.values, dtype=torch.float)\n",
        "# Normalize weights\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "# Move weights to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "# Define the loss function (Weighted Cross Entropy)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "print(\"Class weights for loss function:\", class_weights)\n",
        "print(\"Loss function defined:\", criterion)\n",
        "print(\"Optimizer defined:\", optimizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights for loss function: tensor([0.0356, 0.5333, 0.2138, 0.0356, 0.0485, 0.1333], device='cuda:0')\n",
            "Loss function defined: CrossEntropyLoss()\n",
            "Optimizer defined: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: True\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0003\n",
            "    maximize: False\n",
            "    weight_decay: 0.05\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ae0187a"
      },
      "source": [
        "## 학습 및 평가 함수 구현\n",
        "\n",
        "### Subtask:\n",
        "모델 학습 및 평가를 위한 함수를 구현하고, mixup을 학습 과정에 적용합니다. F1-score와 Accuracy를 평가 지표로 사용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "116159f2"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the training and evaluation functions including mixup and metric calculation as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3861a391",
        "outputId": "752f637f-6ab1-41de-bccc-be35ff95a6c4"
      },
      "source": [
        "from torchmetrics.classification import F1Score, Accuracy\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None, mixup_alpha=0.0):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        if mixup_alpha > 0:\n",
        "            images, labels_a, labels_b, lam = mixup_data(images, labels, mixup_alpha, CFG[\"num_classes\"])\n",
        "\n",
        "        with autocast(enabled=scaler is not None):\n",
        "            outputs = model(images)\n",
        "            if mixup_alpha > 0:\n",
        "                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        if (i + 1) % CFG[\"accum_steps\"] == 0:\n",
        "            if scaler is not None:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate_model(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    f1_metric = F1Score(task=\"multiclass\", num_classes=CFG[\"num_classes\"]).to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.append(preds)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    f1 = f1_metric(all_preds, all_labels)\n",
        "\n",
        "\n",
        "    return epoch_loss, f1.item()\n",
        "\n",
        "print(\"Training and evaluation functions defined.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluation functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26f75e2a"
      },
      "source": [
        "## 모델 학습\n",
        "\n",
        "### Subtask:\n",
        "정의된 모델, 손실 함수, 옵티마이저, 데이터 로더를 사용하여 모델을 학습합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7aac8a"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the main training loop, including data preparation, model training, evaluation, and saving the best model based on validation performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d2e798e",
        "outputId": "51e05022-7d19-4278-97a2-04d51ac4118c"
      },
      "source": [
        "class AIKuthonDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels=None, train_transform=None, val_transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.train_transform = train_transform\n",
        "        self.val_transform = val_transform\n",
        "        self.augment_labels = [1, 2, 5] # Labels to apply augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "            if label in self.augment_labels and self.train_transform:\n",
        "                image = self.train_transform(image=image)[\"image\"]\n",
        "            elif self.val_transform:\n",
        "                 image = self.val_transform(image=image)[\"image\"]\n",
        "            return image, torch.tensor(label, dtype=torch.long)\n",
        "        else:\n",
        "            # Apply validation transform to test images\n",
        "            if self.val_transform:\n",
        "                image = self.val_transform(image=image)[\"image\"]\n",
        "            return image, -1 # Return a placeholder for label\n",
        "\n",
        "# Prepare data for training and validation\n",
        "train_files = scan_files(TRAIND)\n",
        "train_labels = train_meta['label'].values\n",
        "\n",
        "# Stratified k-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=CFG[\"folds\"], shuffle=True, random_state=CFG[\"seed\"])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "best_f1 = 0.0\n",
        "best_model_path = \"best_model.pth\"\n",
        "early_stopping_patience = 5 # Define early stopping patience\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(train_files, train_labels)):\n",
        "    print(f\"===== Fold {fold+1}/{CFG['folds']} =====\")\n",
        "\n",
        "    train_fold_files = [train_files[i] for i in train_index]\n",
        "    train_fold_labels = [train_labels[i] for i in train_index]\n",
        "    val_fold_files = [train_files[i] for i in val_index]\n",
        "    val_fold_labels = [train_labels[i] for i in val_index]\n",
        "\n",
        "    # Create datasets and data loaders\n",
        "    train_dataset = AIKuthonDataset(train_fold_files, train_fold_labels, train_transform=train_transform, val_transform=val_transform)\n",
        "    val_dataset = AIKuthonDataset(val_fold_files, val_fold_labels, val_transform=val_transform)\n",
        "\n",
        "    # Calculate weights for WeightedRandomSampler based on the current fold's training data\n",
        "    fold_label_counts = pd.Series(train_fold_labels).value_counts().sort_index()\n",
        "    fold_class_weights = 1. / fold_label_counts.values\n",
        "    fold_weights = fold_class_weights[train_fold_labels]\n",
        "    fold_weights = torch.DoubleTensor(fold_weights)\n",
        "\n",
        "    train_sampler = WeightedRandomSampler(\n",
        "        weights=fold_weights,\n",
        "        num_samples=len(fold_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CFG[\"batch_size\"],\n",
        "        sampler=train_sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=CFG[\"batch_size\"],\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    # Initialize model, criterion, optimizer, and scaler for each fold\n",
        "    model = build_model(model_name=CFG[\"model_name\"], num_classes=CFG[\"num_classes\"]).to(device)\n",
        "\n",
        "    # Recalculate class weights for the criterion based on the current fold's training data\n",
        "    fold_class_counts_tensor = torch.tensor(fold_label_counts.values, dtype=torch.float).to(device)\n",
        "    fold_class_weights_criterion = 1. / fold_class_counts_tensor\n",
        "    fold_class_weights_criterion = fold_class_weights_criterion / fold_class_weights_criterion.sum()\n",
        "    criterion = nn.CrossEntropyLoss(weight=fold_class_weights_criterion)\n",
        "\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "    scaler = GradScaler() if device.type == 'cuda' else None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(CFG[\"epochs\"]):\n",
        "        print(f\"--- Epoch {epoch+1}/{CFG['epochs']} ---\")\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, mixup_alpha=0.2)\n",
        "        val_loss, val_f1 = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Save best model and implement early stopping\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Saved best model with F1: {best_f1:.4f}\")\n",
        "            epochs_without_improvement = 0 # Reset counter\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= early_stopping_patience:\n",
        "            print(f\"Early stopping after {early_stopping_patience} epochs without improvement.\")\n",
        "            break # Stop training loop for the current fold\n",
        "\n",
        "\n",
        "print(f\"\\nTraining finished. Best validation F1-score: {best_f1:.4f}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 1/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3403317544.py:96: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if device.type == 'cuda' else None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-357726773.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=scaler is not None):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7261\n",
            "Val Loss: 0.8317, Val F1: 0.5649\n",
            "Saved best model with F1: 0.5649\n",
            "--- Epoch 2/20 ---\n",
            "Train Loss: 0.3939\n",
            "Val Loss: 0.4035, Val F1: 0.8510\n",
            "Saved best model with F1: 0.8510\n",
            "--- Epoch 3/20 ---\n",
            "Train Loss: 0.3265\n",
            "Val Loss: 0.3339, Val F1: 0.8840\n",
            "Saved best model with F1: 0.8840\n",
            "--- Epoch 4/20 ---\n",
            "Train Loss: 0.2769\n",
            "Val Loss: 0.2435, Val F1: 0.9320\n",
            "Saved best model with F1: 0.9320\n",
            "--- Epoch 5/20 ---\n",
            "Train Loss: 0.2908\n",
            "Val Loss: 0.2373, Val F1: 0.9309\n",
            "--- Epoch 6/20 ---\n",
            "Train Loss: 0.2617\n",
            "Val Loss: 0.2404, Val F1: 0.9345\n",
            "Saved best model with F1: 0.9345\n",
            "--- Epoch 7/20 ---\n",
            "Train Loss: 0.3155\n",
            "Val Loss: 0.2564, Val F1: 0.9376\n",
            "Saved best model with F1: 0.9376\n",
            "--- Epoch 8/20 ---\n",
            "Train Loss: 0.2048\n",
            "Val Loss: 0.1646, Val F1: 0.9603\n",
            "Saved best model with F1: 0.9603\n",
            "--- Epoch 9/20 ---\n",
            "Train Loss: 0.2490\n",
            "Val Loss: 0.1535, Val F1: 0.9670\n",
            "Saved best model with F1: 0.9670\n",
            "--- Epoch 10/20 ---\n",
            "Train Loss: 0.2300\n",
            "Val Loss: 0.1521, Val F1: 0.9675\n",
            "Saved best model with F1: 0.9675\n",
            "--- Epoch 11/20 ---\n",
            "Train Loss: 0.2616\n",
            "Val Loss: 0.1385, Val F1: 0.9552\n",
            "--- Epoch 12/20 ---\n",
            "Train Loss: 0.2593\n",
            "Val Loss: 0.1686, Val F1: 0.9593\n",
            "--- Epoch 13/20 ---\n",
            "Train Loss: 0.2706\n",
            "Val Loss: 0.1793, Val F1: 0.9670\n",
            "--- Epoch 14/20 ---\n",
            "Train Loss: 0.2374\n",
            "Val Loss: 0.1292, Val F1: 0.9732\n",
            "Saved best model with F1: 0.9732\n",
            "--- Epoch 15/20 ---\n",
            "Train Loss: 0.2661\n",
            "Val Loss: 0.1663, Val F1: 0.9634\n",
            "--- Epoch 16/20 ---\n",
            "Train Loss: 0.2437\n",
            "Val Loss: 0.1664, Val F1: 0.9639\n",
            "--- Epoch 17/20 ---\n",
            "Train Loss: 0.2541\n",
            "Val Loss: 0.1517, Val F1: 0.9716\n",
            "--- Epoch 18/20 ---\n",
            "Train Loss: 0.2465\n",
            "Val Loss: 0.1724, Val F1: 0.9634\n",
            "--- Epoch 19/20 ---\n",
            "Train Loss: 0.2615\n",
            "Val Loss: 0.1310, Val F1: 0.9753\n",
            "Saved best model with F1: 0.9753\n",
            "--- Epoch 20/20 ---\n",
            "Train Loss: 0.2084\n",
            "Val Loss: 0.1293, Val F1: 0.9768\n",
            "Saved best model with F1: 0.9768\n",
            "===== Fold 2/5 =====\n",
            "--- Epoch 1/20 ---\n",
            "Train Loss: 0.7140\n",
            "Val Loss: 0.9048, Val F1: 0.5253\n",
            "--- Epoch 2/20 ---\n",
            "Train Loss: 0.3328\n",
            "Val Loss: 0.3991, Val F1: 0.8582\n",
            "--- Epoch 3/20 ---\n",
            "Train Loss: 0.3510\n",
            "Val Loss: 0.3617, Val F1: 0.8747\n",
            "--- Epoch 4/20 ---\n",
            "Train Loss: 0.2742\n",
            "Val Loss: 0.2652, Val F1: 0.9216\n",
            "--- Epoch 5/20 ---\n",
            "Train Loss: 0.2937\n",
            "Val Loss: 0.2731, Val F1: 0.9294\n",
            "Early stopping after 5 epochs without improvement.\n",
            "===== Fold 3/5 =====\n",
            "--- Epoch 1/20 ---\n",
            "Train Loss: 0.7286\n",
            "Val Loss: 0.8506, Val F1: 0.5593\n",
            "Early stopping after 5 epochs without improvement.\n",
            "===== Fold 4/5 =====\n",
            "--- Epoch 1/20 ---\n",
            "Train Loss: 0.8280\n",
            "Val Loss: 0.9103, Val F1: 0.5149\n",
            "Early stopping after 5 epochs without improvement.\n",
            "===== Fold 5/5 =====\n",
            "--- Epoch 1/20 ---\n",
            "Train Loss: 0.7459\n",
            "Val Loss: 0.8058, Val F1: 0.5921\n",
            "Early stopping after 5 epochs without improvement.\n",
            "\n",
            "Training finished. Best validation F1-score: 0.9768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model = build_model(model_name=CFG[\"model_name\"], num_classes=CFG[\"num_classes\"]).to(device)\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()\n",
        "\n",
        "# Prepare test data\n",
        "test_files = scan_files(TESTD)\n",
        "# Generate test IDs based on the number of test files and their naming convention\n",
        "test_ids = [int(os.path.splitext(os.path.basename(f))[0]) for f in test_files]\n",
        "test_ids = sorted(test_ids) # Ensure IDs are in order\n",
        "\n",
        "test_dataset = AIKuthonDataset(test_files, labels=None, val_transform=val_transform) # No labels for test set\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CFG[\"batch_size\"],\n",
        "    num_workers=CFG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Perform inference\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader: # No labels in test_loader\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "\n",
        "# Create submission file\n",
        "submission_df = pd.DataFrame({'id': test_ids, 'label': all_preds})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully.\")\n",
        "display(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "e2xknzisWHxH",
        "outputId": "5d54882b-f57d-44a2-85c6-bf972710e719"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file 'submission.csv' created successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   id  label\n",
              "0   1      4\n",
              "1   2      3\n",
              "2   3      5\n",
              "3   4      1\n",
              "4   5      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82ea8b87-6785-47c8-a4ac-8945a1360de7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82ea8b87-6785-47c8-a4ac-8945a1360de7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82ea8b87-6785-47c8-a4ac-8945a1360de7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82ea8b87-6785-47c8-a4ac-8945a1360de7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3e92bf0c-13f7-4e77-bbc7-703ceb8df5ea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e92bf0c-13f7-4e77-bbc7-703ceb8df5ea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3e92bf0c-13f7-4e77-bbc7-703ceb8df5ea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(submission_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac95479d"
      },
      "source": [
        "## 태스크 완료\n",
        "\n",
        "클래스 불균형 문제를 해결하기 위해 EfficientNet-B0 모델, dropout, mixup 기법을 사용하여 이미지 크기를 224x224로 조정하고 모델 학습 및 평가를 진행했습니다. 또한, 테스트 데이터에 대한 추론을 수행하고 Kaggle 제출 형식에 맞는 `submission.csv` 파일을 성공적으로 생성했습니다.\n",
        "\n",
        "**주요 구현 내용:**\n",
        "\n",
        "- 데이터셋 클래스 불균형 확인 및 WeightedRandomSampler를 사용한 오버샘플링 적용\n",
        "- Albumentations를 활용한 데이터 증강 및 Mixup 구현\n",
        "- EfficientNet-B0 모델 로드 및 클래스 수에 맞게 수정, Dropout 적용\n",
        "- 클래스 가중치를 고려한 Cross-Entropy 손실 함수 및 AdamW 옵티마이저 정의\n",
        "- F1-score를 평가 지표로 사용한 학습 및 평가 함수 구현\n",
        "- Stratified K-Fold 교차 검증 및 조기 종료(Early Stopping) 적용\n",
        "- 테스트 데이터셋에 대한 추론 및 제출 파일 생성\n",
        "\n",
        "제출 파일인 `submission.csv`는 현재 디렉토리에 저장되었습니다. 이 파일을 Kaggle 대회에 제출하시면 됩니다."
      ]
    }
  ]
}